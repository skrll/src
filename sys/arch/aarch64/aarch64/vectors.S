/*	$NetBSD: vectors.S,v 1.18 2020/08/12 13:19:35 skrll Exp $	*/

#include <aarch64/asm.h>
#include <aarch64/locore.h>

#include "assym.h"

#include "opt_cpuoptions.h"
#include "opt_ddb.h"
#include "opt_dtrace.h"

RCSID("$NetBSD$")

	ARMV8_DEFINE_OPTIONS

#ifdef KDTRACE_HOOKS
/*
 * dtrace needs to emulate  stp x29,x30,[sp,#-FRAMESIZE]!   where
 * FRAMESIZE can be as large as 512, so create a 512-byte buffer
 * between the interrupted code's frame and our struct trapframe.
 */
#define	TRAP_FRAMESIZE	(TF_SIZE + 512)
#else
#define	TRAP_FRAMESIZE	TF_SIZE
#endif

/*
 * Template for the handler functions.
 */
.macro	vector_func, func, el, label, tpidr
	.align 7	/* cacheline-aligned */

ENTRY_NBTI(\func)
	.cfi_startproc
	.if \el == 1
	/* need to allocate stack on el1 */
	sub	sp, sp, #TRAP_FRAMESIZE
	.cfi_def_cfa_offset TRAP_FRAMESIZE
	.else
	.cfi_def_cfa_offset 0
	.endif

	stp	x0, x1, [sp, #TF_X0]
	.cfi_rel_offset x0, TF_X0
	.cfi_rel_offset x1, TF_X1

	stp	x2, x3, [sp, #TF_X2]
	.cfi_rel_offset x2, TF_X2
	.cfi_rel_offset x3, TF_X3

	stp	x4, x5, [sp, #TF_X4]
	.cfi_rel_offset x4, TF_X4
	.cfi_rel_offset x5, TF_X5

	stp	x6, x7, [sp, #TF_X6]
	.cfi_rel_offset x6, TF_X6
	.cfi_rel_offset x7, TF_X7

	stp	x8, x9, [sp, #TF_X8]
	.cfi_rel_offset x8, TF_X8
	.cfi_rel_offset x9, TF_X9

	stp	x10, x11, [sp, #TF_X10]
	.cfi_rel_offset x10, TF_X10
	.cfi_rel_offset x11, TF_X11

	stp	x12, x13, [sp, #TF_X12]
	.cfi_rel_offset x12, TF_X12
	.cfi_rel_offset x13, TF_X13

	stp	x14, x15, [sp, #TF_X14]
	.cfi_rel_offset x14, TF_X14
	.cfi_rel_offset x15, TF_X15

	stp	x16, x17, [sp, #TF_X16]
	.cfi_rel_offset x16, TF_X16
	.cfi_rel_offset x17, TF_X17

	str	x18, [sp, #TF_X18]
	.cfi_rel_offset x18, TF_X18

	stp	x19, x20, [sp, #TF_X19]
	.cfi_rel_offset x19, TF_X19
	.cfi_rel_offset x20, TF_X20

	stp	x21, x22, [sp, #TF_X21]
	.cfi_rel_offset x21, TF_X21
	.cfi_rel_offset x22, TF_X22

	stp	x23, x24, [sp, #TF_X23]
	.cfi_rel_offset x23, TF_X23
	.cfi_rel_offset x24, TF_X24

	stp	x25, x26, [sp, #TF_X25]
	.cfi_rel_offset x25, TF_X25
	.cfi_rel_offset x26, TF_X26

	stp	x27, x28, [sp, #TF_X27]
	.cfi_rel_offset x27, TF_X27
	.cfi_rel_offset x28, TF_X28

	stp	x29, lr, [sp, #TF_X29]

	.cfi_rel_offset x29, TF_X29
	.cfi_rel_offset lr, TF_X30

	/* get sp and elr */
	.if \el == 0
	mrs	x20, sp_el0
	.else
	/* sp was already adjusted, so adjust x20 back */
	add	x20, sp, #TRAP_FRAMESIZE
	.endif
	mrs	x21, elr_el1

	/* store sp and elr */
	.if TF_SP + 8 == TF_PC
	stp	x20, x21, [sp, #TF_SP]
	.else
	str	x20, [sp, #TF_SP]
	str	x21, [sp, #TF_PC]
	.endif
	.cfi_rel_offset sp, TF_SP
	.cfi_rel_offset lr, TF_PC

	mrs	x22, spsr_el1
	str	x22, [sp, #TF_SPSR]

	mrs	x23, esr_el1
	mrs	x24, far_el1

	.if TF_ESR + 8 == TF_FAR
	stp	x23, x24, [sp, #TF_ESR]
	.else
	str	x23, [sp, #TF_ESR]
	str	x24, [sp, #TF_FAR]
	.endif

	.if \el == 0
	/* curlwp->l_private = tpidr{,ro}_el0 */
	mrs	x1, tpidr_el1		/* x1 = curlwp */
	mrs	x0, tpidr\tpidr\()_el0
	str	x0, [x1, #L_PRIVATE]	/* curlwp->l_private = tpidr{,ro}_el0 */

#ifdef ARMV83_PAC
	/* Switch to the kern PAC key. */
	adrl	x4, _C_LABEL(aarch64_pac_enabled)
	ldr	w4, [x4]
	cbz	w4, 1f
	ldp	x5, x6, [x1, #L_MD_IA_KERN]
	msr	APIAKeyLo_EL1, x5
	msr	APIAKeyHi_EL1, x6
1:
#endif
	.endif

	adr	lr, el\el\()_trap_exit	/* el[01]_trap_exit */
	mov	x0, sp
#ifdef DDB
	mov	x29, sp			/* for backtrace */
#endif
	b	\label
	.cfi_def_cfa_offset 0
	.cfi_endproc
END(\func)
.endm

/*
 * The vector_entry macro must be small enough to fit 0x80 bytes! We just jump
 * into the proper function, so this constraint is always respected.
 */
.macro	vector_entry, func
	.global vec_\func
	.align 7	/* aligned 0x80 */
vec_\func:
	.cfi_startproc
	b	\func
	.cfi_endproc
.endm

/*
 * The functions.
 */
vector_func	el1t_sync_handler,  1, trap_el1t_sync
vector_func	el1t_irq_handler,   1, trap_el1t_irq
vector_func	el1t_fiq_handler,   1, trap_el1t_fiq
vector_func	el1t_error_handler, 1, trap_el1t_error

vector_func	el1h_sync_handler,  1, trap_el1h_sync
vector_func	el1h_intr_handler,  1, interrupt
vector_func	el1h_fiq_handler,   1, trap_el1h_fiq
vector_func	el1h_error_handler, 1, trap_el1h_error

vector_func	el0_sync_handler,  0, trap_el0_sync
vector_func	el0_intr_handler,  0, interrupt
vector_func	el0_fiq_handler,   0, trap_el0_fiq
vector_func	el0_error_handler, 0, trap_el0_error

vector_func	el0_32sync_handler,  0, trap_el0_32sync, ro
vector_func	el0_32intr_handler,  0, interrupt, ro
vector_func	el0_32fiq_handler,   0, trap_el0_32fiq, ro
vector_func	el0_32error_handler, 0, trap_el0_32error, ro

/*
 * The vector table. Must be aligned to 2048.
 */
	.align 11
ENTRY_NBTI(el1_vectors)
	/*
	 * Exception taken from current Exception Level with SP_EL0.
	 * (These shouldn't happen)
	 */
	vector_entry	el1t_sync_handler
	vector_entry	el1t_irq_handler
	vector_entry	el1t_fiq_handler
	vector_entry	el1t_error_handler

	/*
	 * Exception taken from current Exception Level with SP_EL1.
	 * There are entries for exceptions caused in EL1 (kernel exceptions).
	 */
	vector_entry	el1h_sync_handler
	vector_entry	el1h_intr_handler
	vector_entry	el1h_fiq_handler
	vector_entry	el1h_error_handler

	/*
	 * Exception taken from lower Exception Level which is using AArch64.
	 * There are entries for exceptions caused in EL0 (native user exceptions).
	 */
	vector_entry	el0_sync_handler
	vector_entry	el0_intr_handler
	vector_entry	el0_fiq_handler
	vector_entry	el0_error_handler

	/*
	 * Exception taken from lower Exception Level which is using AArch32.
	 * There are entries for exceptions caused in EL0 (compat user exceptions).
	 */
	vector_entry	el0_32sync_handler
	vector_entry	el0_32intr_handler
	vector_entry	el0_32fiq_handler
	vector_entry	el0_32error_handler
END(el1_vectors)

	.macro unwind_x0_x2
	ldp	x0, x1, [sp, #TF_X0]
	ldr	x2, [sp, #TF_X2]
	.endm

	.macro unwind_x3_x30
	.cfi_def_cfa_offset 0

	ldp	x3, x4, [sp, #TF_X3]
	.cfi_restore x4
	.cfi_restore x3
	ldp	x5, x6, [sp, #TF_X5]
	.cfi_restore x6
	.cfi_restore x5
	ldp	x7, x8, [sp, #TF_X7]
	.cfi_restore x8
	.cfi_restore x7
	ldp	x9, x10, [sp, #TF_X9]
	.cfi_restore x10
	.cfi_restore x9
	ldp	x11, x12, [sp, #TF_X11]
	.cfi_restore x12
	.cfi_restore x11
	ldp	x13, x14, [sp, #TF_X13]
	.cfi_restore x14
	.cfi_restore x13
	ldp	x15, x16, [sp, #TF_X15]
	.cfi_restore x16
	.cfi_restore x15
	ldp	x17, x18, [sp, #TF_X17]
	.cfi_restore x18
	.cfi_restore x17
	ldp	x19, x20, [sp, #TF_X19]
	.cfi_restore x20
	.cfi_restore x19
	ldp	x21, x22, [sp, #TF_X21]
	.cfi_restore x22
	.cfi_restore x21
	ldp	x23, x24, [sp, #TF_X23]
	.cfi_restore x24
	.cfi_restore x23
	ldp	x25, x26, [sp, #TF_X25]
	.cfi_restore x26
	.cfi_restore x25
	ldp	x27, x28, [sp, #TF_X27]
	.cfi_restore x28
	.cfi_restore x27
	ldp	x29, lr, [sp, #TF_X29]
	.cfi_restore lr
	.cfi_restore x29
	.endm


/*
 * EL1 exception return for trap and interrupt.
 */
#ifdef DDB
ENTRY_NP(el1_trap)
	nop				/* dummy for DDB backtrace (for lr-4) */
#endif
ENTRY_NP(el1_trap_exit)
	.cfi_startproc
	DISABLE_INTERRUPT		/* make sure I|F marked */

	unwind_x3_x30

#if TF_PC + 8 == TF_SPSR
	ldp	x0, x1, [sp, #TF_PC]
#else
	ldr	x0, [sp, #TF_PC]
	ldr	x1, [sp, #TF_SPSR]
#endif

	msr	elr_el1, x0		/* exception pc */
	msr	spsr_el1, x1		/* exception pstate */

	/*
	 * cpu_jump_onfault() modify tf->tf_sp, therefore
	 * we need to restore sp from trapframe,
	 * and unwind x0-x2 without sp.
	 */
	mov	x0, sp
	.cfi_def_cfa_register   x0

	ldr	x1, [x0, #TF_SP]
	mov	sp, x1
	.cfi_restore sp
	ldp	x1, x2, [x0, #TF_X1]
	.cfi_restore x1
	.cfi_restore x2
	ldr	x0, [x0, #TF_X0]
	.cfi_restore x0

	.cfi_def_cfa_offset 0
	ERET
	.cfi_endproc
END(el1_trap_exit)
#ifdef DDB
END(el1_trap)
#endif

/*
 * EL0 exception return for trap, interrupt and syscall with
 * possible AST processing.
 */
#ifdef DDB
ENTRY_NP(el0_trap)
	nop				/* dummy for DDB backtrace (for lr-4) */
#endif
ENTRY_NP(el0_trap_exit)
	.cfi_startproc
	DISABLE_INTERRUPT		/* make sure I|F marked */
1:
	/* while (curlwp->l_md.md_astpending != 0) { */
	mrs	x8, tpidr_el1
	ldr	w9, [x8, #L_MD_ASTPENDING]
	cbz	w9, 9f

	/* curlwp->l_md.md_astpending = 0; */
	str	xzr, [x8, #L_MD_ASTPENDING]

	/*  trap_doast(tf); */
	ENABLE_INTERRUPT
	mov	x0, sp
	bl	_C_LABEL(trap_doast)
	DISABLE_INTERRUPT
	b	1b
	/* } */
9:

	mrs	x9, tpidr_el1
	ldr	x23, [x9, #L_MD_CPACR]
	msr	cpacr_el1, x23		/* FP unit EL0 handover */
	isb				/* necessary? */

	ldr	x0, [x9, #L_PRIVATE]	/* tpidr_el0 = curlwp->l_private */
	msr	tpidr_el0, x0
#ifdef COMPAT_NETBSD32
	msr	tpidrro_el0, x0
#endif

#ifdef ARMV83_PAC
	/* Switch to the user PAC key. */
	adrl	x4, _C_LABEL(aarch64_pac_enabled)
	ldr	w4, [x4]
	cbz	w4, 1f
	ldp	x5, x6, [x9, #L_MD_IA_USER]
	msr	APIAKeyLo_EL1, x5
	msr	APIAKeyHi_EL1, x6
1:
#endif

	unwind_x3_x30

#if TF_PC + 8 == TF_SPSR
	ldp	x0, x1, [sp, #TF_PC]
#else
	ldr	x0, [sp, #TF_PC]
	ldr	x1, [sp, #TF_SPSR]
#endif
	ldr	x2, [sp, #TF_SP]
	msr	elr_el1, x0		/* exception pc */
	msr	spsr_el1, x1		/* exception pstate */
	msr	sp_el0, x2		/* restore EL0 stack */

	/* if the process is traced, enable MDSCR_EL1.SS */
	tbz	x1, #SPSR_SS_SHIFT, 1f
	mrs	x0, mdscr_el1
	orr	x0, x0, #MDSCR_SS
	msr	mdscr_el1, x0
1:
	unwind_x0_x2

	/* leave sp at l_md.md_utf, return back to EL0 user process */
	ERET
	.cfi_endproc
END(el0_trap_exit)
#ifdef DDB
END(el0_trap)
#endif
